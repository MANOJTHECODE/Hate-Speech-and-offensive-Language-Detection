{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwordcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m WordCloud\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompose\u001b[39;00m \u001b[39mimport\u001b[39;00m ColumnTransformer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('../input/hate-speech-and-offensive-language-dataset/labeled_data.csv')\n",
    "dataset.head()\n",
    "\n",
    "# Cleaning the texts\n",
    "corpus = []\n",
    "for i in range(0, 24783):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', dt_trasformed['tweet'][i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  ps = PorterStemmer()\n",
    "  all_stopwords = stopwords.words('english')\n",
    "  all_stopwords.remove('not')\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)\n",
    "  corpus.append(review)\n",
    "\n",
    "cv = CountVectorizer(max_features = 2000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_hate, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# Finding the best models to predict hate speech\n",
    "# Naive Bayes\n",
    "classifier_np = GaussianNB()\n",
    "classifier_np.fit(X_train, y_train)\n",
    "\n",
    "# Decision Tree\n",
    "classifier_dt = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "classifier_dt.fit(X_train, y_train)\n",
    "\n",
    "# KNN\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "classifier_knn.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression\n",
    "classifier_lr = LogisticRegression(random_state=0)\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "classifier_rf = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "\n",
    "# Making the Confusion Matrix for each model\n",
    "# Naive Bayes\n",
    "y_pred_np = classifier_np.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_np)\n",
    "print(cm)\n",
    "\n",
    "# Decision Tree\n",
    "y_pred_dt = classifier_dt.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_dt)\n",
    "print(cm)\n",
    "\n",
    "# Logistic Regression\n",
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "print(cm)\n",
    "\n",
    "# Random Forest\n",
    "y_pred_rf = classifier_rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "print(cm)\n",
    "\n",
    "rf_score = accuracy_score(y_test, y_pred_rf)\n",
    "lr_score = accuracy_score(y_test, y_pred_lr)\n",
    "dt_score = accuracy_score(y_test, y_pred_dt)\n",
    "np_score = accuracy_score(y_test, y_pred_np)\n",
    "\n",
    "print('Random Forest Accuracy:', str(rf_score))\n",
    "print('Logistic Regression Accuracy:', str(lr_score))\n",
    "print('Decision Tree Accuracy:', str(dt_score))\n",
    "print('Naive Bayes Accuracy:', str(np_score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
